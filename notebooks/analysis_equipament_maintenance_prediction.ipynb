{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46e144cf",
      "metadata": {
        "id": "46e144cf"
      },
      "source": [
        "# Equipament Maintenance Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install mlflow\n",
        "# %pip install imblearn\n",
        "# %pip install xgboost"
      ],
      "metadata": {
        "id": "qkRQ2ZjJeTTQ",
        "outputId": "8eb8fc19-0f71-4314-fdca-f79ce5b475a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qkRQ2ZjJeTTQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: mlflow-skinny==3.1.1 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.4)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.59.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.35.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (1.35.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow) (0.56b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.7.14)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.11/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc477b4",
      "metadata": {
        "id": "ecc477b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "import os\n",
        "from pathlib import Path\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfcb9e6",
      "metadata": {
        "id": "abfcb9e6"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = Path(__name__).resolve().parent.parent\n",
        "data_folder_path = os.path.join(ROOT_PATH, \"data\")\n",
        "\n",
        "data_path = os.path.join(data_folder_path, \"equipament-cycles.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a504dfd3",
      "metadata": {
        "id": "a504dfd3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(data_path, header=0, sep=\",\")\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d975ed81",
      "metadata": {
        "id": "d975ed81"
      },
      "outputs": [],
      "source": [
        "data.loc[data[\"Machine failure\"] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7e26e0",
      "metadata": {
        "id": "ab7e26e0"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ee2b8c",
      "metadata": {
        "id": "73ee2b8c"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99a9e58",
      "metadata": {
        "id": "e99a9e58"
      },
      "outputs": [],
      "source": [
        "cols_drop = [\"UDI\", \"Product ID\", \"Type\", \"Machine failure\", \"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
        "temp = data.drop(cols_drop, axis=1)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(temp.columns):\n",
        "    ax = axes[i]\n",
        "    temp.boxplot(column=col, ax=ax)\n",
        "    ax.set_title(f\"{col.title()} BoxPlot Analysis\")\n",
        "    ax.set_ylabel(\"Value\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3e540d",
      "metadata": {
        "id": "8b3e540d"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(temp.columns):\n",
        "    ax = axes[i]\n",
        "    temp.hist(column=col, ax=ax, grid=False, bins=50)\n",
        "    ax.set_title(f\"{col.title()} BoxPlot Analysis\")\n",
        "    ax.set_ylabel(\"Value\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab06b13",
      "metadata": {
        "id": "4ab06b13"
      },
      "source": [
        "If the machine goes further than the top quantile, does it generate more failure?\n",
        "\n",
        "H0 -> Rotation on outlier parameters does not have impact<br>\n",
        "H1 -> Rotation on outlier parameters does have impact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7373098",
      "metadata": {
        "id": "c7373098"
      },
      "outputs": [],
      "source": [
        "q1 = data[\"Rotational speed [rpm]\"].quantile(0.25)\n",
        "q3 = data[\"Rotational speed [rpm]\"].quantile(0.75)\n",
        "\n",
        "iqr = q3 - q1\n",
        "superior_limit = q3 + 1.5 * iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c185e5",
      "metadata": {
        "id": "66c185e5"
      },
      "outputs": [],
      "source": [
        "couting_over_limit = data.loc[data[\"Rotational speed [rpm]\"]>=superior_limit][\"Machine failure\"].value_counts()\n",
        "couting_under_limit = data.loc[data[\"Rotational speed [rpm]\"]<superior_limit][\"Machine failure\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd073bc4",
      "metadata": {
        "id": "bd073bc4"
      },
      "outputs": [],
      "source": [
        "chance_of_failure_above_limit = (\n",
        "    couting_over_limit[1] / couting_over_limit.sum()\n",
        "    ) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45cdcc8",
      "metadata": {
        "id": "e45cdcc8"
      },
      "outputs": [],
      "source": [
        "chance_of_failure_under_limit = (\n",
        "    couting_under_limit[1] / couting_under_limit.sum()\n",
        "    ) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89e5d16",
      "metadata": {
        "id": "d89e5d16"
      },
      "outputs": [],
      "source": [
        "print(f\"Above Limit: {chance_of_failure_above_limit.round(2)} %\")\n",
        "print(f\"Under Limit: {chance_of_failure_under_limit.round(2)} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548775a5",
      "metadata": {
        "id": "548775a5"
      },
      "source": [
        "Although we have a higher chance of failure with the equipament running up to the outliers values, it's not conclusive that it generate a failure.<br>\n",
        "To really understand the impact of rotation on failure, we would have to take a look at the equipament manual and evaluate its operations limits.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83bae7df",
      "metadata": {
        "id": "83bae7df"
      },
      "source": [
        "Types of procuts manufactured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ce82ef",
      "metadata": {
        "id": "37ce82ef"
      },
      "outputs": [],
      "source": [
        "print(f\"Products: {data[\"Type\"].unique()}\\n\")\n",
        "print(f\"Counting: {data[\"Type\"].value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24f2a69",
      "metadata": {
        "id": "f24f2a69"
      },
      "outputs": [],
      "source": [
        "resume_failure = data.loc[data[\"Machine failure\"]==1]\n",
        "resume_type = resume_failure.groupby([\"Type\"]).agg({\"Machine failure\": \"count\"}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada58b66",
      "metadata": {
        "id": "ada58b66"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(13, 6))\n",
        "\n",
        "bars = ax.barh(width=resume_type[\"Machine failure\"], y=resume_type[\"Type\"])\n",
        "ax.set_ylabel(\"Product Type\")\n",
        "ax.set_xlabel(\"Count\")\n",
        "ax.set_title(\"Counting failures of each product type manufactured\", loc=\"left\")\n",
        "ax.bar_label(bars, padding=3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12cf1b6e",
      "metadata": {
        "id": "12cf1b6e"
      },
      "source": [
        "Checking normalization on the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d40aa1",
      "metadata": {
        "id": "b5d40aa1"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5c6bd3",
      "metadata": {
        "id": "6e5c6bd3"
      },
      "outputs": [],
      "source": [
        "cols_to_transform = list()\n",
        "\n",
        "for col in data.drop(cols_drop, axis=1).columns:\n",
        "\n",
        "    test = stats.normaltest(data[col])\n",
        "    pvalue = test.pvalue\n",
        "\n",
        "    alpha = 0.05\n",
        "\n",
        "    if pvalue > alpha:\n",
        "        print(f\"column: {col}  /  p-value: {pvalue}\")\n",
        "        print('Não rejeita H0: Os dados parecem ser normalmente distribuídos.\\n')\n",
        "    else:\n",
        "        cols_to_transform.append(col)\n",
        "        print(f\"column: {col}  /  p-value: {pvalue}\")\n",
        "        print('Rejeita H0: Os dados não seguem uma distribuição normal.\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc71c45",
      "metadata": {
        "id": "1bc71c45"
      },
      "outputs": [],
      "source": [
        "data_transformed = data.copy()\n",
        "\n",
        "for col in cols_to_transform:\n",
        "    data_array = np.array(data[col]).reshape(-1, 1)\n",
        "    transformer = PowerTransformer(method=\"yeo-johnson\")\n",
        "    data_transformed[f\"{col}_t\"] = transformer.fit_transform(data_array).flatten()\n",
        "\n",
        "    data_transformed.drop(col, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf77fe4c",
      "metadata": {
        "id": "cf77fe4c"
      },
      "source": [
        "Later, I'll try both ways and understand which fits better. Normalized data or original data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6094f570",
      "metadata": {
        "id": "6094f570"
      },
      "source": [
        "The structure of the modeling may include a failure prediction before the the failure itself.<br>\n",
        "\n",
        "To do that, we can get the value of failure and offset it to the previous cycles, creating the possibility of early prediction before failure X cycles before real failure.<br>\n",
        "<br>\n",
        "We'll try to make the prediction in a range of 3 cycles before failure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e135baa",
      "metadata": {
        "id": "7e135baa"
      },
      "outputs": [],
      "source": [
        "data_new = data.drop([col for col in cols_drop if col != \"Machine failure\" and col != \"Type\"], axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3b9210",
      "metadata": {
        "id": "6c3b9210"
      },
      "outputs": [],
      "source": [
        "for i in data_new.index:\n",
        "    status = data_new.loc[i, \"Machine failure\"]\n",
        "    if status == 1 and i > 3:\n",
        "        data_new.loc[i-1, \"Machine failure\"] = 1\n",
        "        data_new.loc[i-2, \"Machine failure\"] = 1\n",
        "        data_new.loc[i-3, \"Machine failure\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9dd5ad9",
      "metadata": {
        "id": "f9dd5ad9"
      },
      "outputs": [],
      "source": [
        "data_new[\"Machine failure\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "067a5281",
      "metadata": {
        "id": "067a5281"
      },
      "outputs": [],
      "source": [
        "non_failure = data_new[\"Machine failure\"].value_counts()[0]\n",
        "failure = data_new[\"Machine failure\"].value_counts()[1]\n",
        "\n",
        "diff = (failure / non_failure) -1\n",
        "\n",
        "cutting = 0.2\n",
        "\n",
        "if abs(diff) > cutting:\n",
        "    print(f\"Difference {diff.round(3) * 100}%\\n\")\n",
        "    print(\"Data is unbalanced. Treatment of balancing is required.\")\n",
        "else:\n",
        "    print(f\"Difference {diff.round(3) * 100}\\n\")\n",
        "    print(\"Data is balanced. No treatment needed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebdf003",
      "metadata": {
        "id": "0ebdf003"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "counting = data_new.groupby([\"Machine failure\"]).agg({\"Type\": \"count\"}).reset_index()\n",
        "\n",
        "bars = ax.bar(height=counting[\"Type\"], x=counting[\"Machine failure\"])\n",
        "ax.bar_label(bars)\n",
        "ax.set_xlabel(\"Labels\")\n",
        "ax.set_ylabel(\"Counting\")\n",
        "ax.set_title(\"Counting values of each label\", loc=\"left\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d6ec4f",
      "metadata": {
        "id": "e6d6ec4f"
      },
      "source": [
        "### Balancing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51862d94",
      "metadata": {
        "id": "51862d94"
      },
      "outputs": [],
      "source": [
        "X = data_new.drop([\"Machine failure\"], axis=1)\n",
        "y = data_new.loc[:, \"Machine failure\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed003db",
      "metadata": {
        "id": "eed003db"
      },
      "source": [
        "We've got important variable called Type. Although, this variable is a categorical value.<br>\n",
        "<br>\n",
        "As soons as I may use this variable, I'll convert it to binary values with the One-Hot-Encoding method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae7a006",
      "metadata": {
        "id": "eae7a006"
      },
      "outputs": [],
      "source": [
        "X = pd.get_dummies(X, columns=[\"Type\"], dtype=int)\n",
        "\n",
        "# I'll not drop de first dummy. I'll keep all of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce0ee67",
      "metadata": {
        "id": "9ce0ee67"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE()\n",
        "X_b, y_b = smote.fit_resample(X, y)\n",
        "\n",
        "data_balanced = pd.concat([X_b, y_b], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69babaab",
      "metadata": {
        "id": "69babaab"
      },
      "outputs": [],
      "source": [
        "data_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95dbb9b9",
      "metadata": {
        "id": "95dbb9b9"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "counting = data_balanced.groupby([\"Machine failure\"]).agg({\"Type_H\": \"count\"}).reset_index()\n",
        "\n",
        "bars = ax.bar(height=counting[\"Type_H\"], x=counting[\"Machine failure\"])\n",
        "ax.bar_label(bars)\n",
        "ax.set_xlabel(\"Labels\")\n",
        "ax.set_ylabel(\"Counting\")\n",
        "ax.set_title(\"Counting values of each label\", loc=\"left\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3529d267",
      "metadata": {
        "id": "3529d267"
      },
      "outputs": [],
      "source": [
        "data_balanced.corr(method=\"pearson\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2160a0",
      "metadata": {
        "id": "1c2160a0"
      },
      "outputs": [],
      "source": [
        "data_balanced.corr(method=\"kendall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6388bae8",
      "metadata": {
        "id": "6388bae8"
      },
      "outputs": [],
      "source": [
        "non_linear_relation = dict()\n",
        "for col in data_balanced.columns:\n",
        "    x1 = np.array(data_balanced[\"Machine failure\"]).reshape(-1, 1)\n",
        "    x2 = np.array(data_balanced[col]).reshape(-1, 1)\n",
        "\n",
        "    coef = mutual_info_regression(x1, x2)\n",
        "\n",
        "    non_linear_relation[col] = coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4728f71",
      "metadata": {
        "id": "c4728f71"
      },
      "outputs": [],
      "source": [
        "non_linear_relation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d25ec9",
      "metadata": {
        "id": "96d25ec9"
      },
      "source": [
        "There is a non linear relation between the variables with the Failures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96ba09d",
      "metadata": {
        "id": "c96ba09d"
      },
      "source": [
        "Does the data have multicolinearity? Let's evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9adc15",
      "metadata": {
        "id": "ca9adc15"
      },
      "outputs": [],
      "source": [
        "vif_data = pd.DataFrame()\n",
        "X_vif = data_balanced.drop([\"Machine failure\"], axis=1)\n",
        "vif_data[\"features\"] = X_vif.columns\n",
        "\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(len(X_vif.columns))]\n",
        "\n",
        "vif_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fed7595",
      "metadata": {
        "id": "7fed7595"
      },
      "source": [
        "- 'Air Temperature [K]' and 'Process Temperature [K]' contains a huge multicolinearity. Depending on how the model behives, We can drop it.<br>\n",
        "- 'Rotational speed [rpm]' and 'Torque [Nm]' also contains multicolinearity. Which make sense because rotary machinery have a Torque and Rotational Speed.<br>\n",
        "- All other variabels satisfy the Variation inflation Factor Limits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a072cebd",
      "metadata": {
        "id": "a072cebd"
      },
      "source": [
        "In this case, we can Drop one of the columns between: 'Air Temperature [K]' and 'Process Temperature [K]', and also drop one between 'Rotational speed [rpm]' and 'Torque [Nm]'.<br>\n",
        "It'll all depend on how does the model behive to the modeling, and if the column is statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ebe84e",
      "metadata": {
        "id": "96ebe84e"
      },
      "source": [
        "### Separate Original data into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cae664d",
      "metadata": {
        "id": "3cae664d"
      },
      "outputs": [],
      "source": [
        "X_b.columns = [col.replace(\"[K]\", \"\").replace(\"[rpm]\", \"\").replace(\"[Nm]\", \"\").replace(\"[min]\", \"\") for col in X_b.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19e3362",
      "metadata": {
        "id": "a19e3362"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_b, y_b, test_size=0.2, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98726216",
      "metadata": {
        "id": "98726216"
      },
      "source": [
        "### Model experiment - Original Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad51147",
      "metadata": {
        "id": "0ad51147"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
        "    \"XGBoostClassifier\": XGBClassifier(),\n",
        "    \"SVC\": SVC(),\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
        "    \"HistGradientBoostingClassifier\": HistGradientBoostingClassifier(),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ead6120",
      "metadata": {
        "id": "2ead6120"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"RandomForestClassifier\": {\n",
        "        \"n_estimators\": [100, 150, 180, 200],\n",
        "        # \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "        # \"max_depth\": [None, 1, 3, 5, 7, 9],\n",
        "        \"min_samples_split\": [2, 5, 8, 11],\n",
        "        # \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "        \"min_samples_leaf\": [2, 5, 9]\n",
        "    },\n",
        "    \"XGBoostClassifier\": {\n",
        "        \"n_estimators\": [100, 150, 180, 200],\n",
        "        # \"learning_rate\": [0.3, 0.1, 0.01, 0.005],\n",
        "        \"max_depth\": [6, 12, 24, 44],\n",
        "    },\n",
        "    \"SVC\": {\n",
        "        \"C\": [1.0, 1.5, 2.0],\n",
        "        # \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"],\n",
        "        # \"degree\": [3, 5, 7, 9],\n",
        "        \"gamma\": [\"scale\", \"auto\"],\n",
        "    },\n",
        "    \"GaussianNB\": {\n",
        "        \"var_smoothing\": [1e-9, 1e-6, 1e-3, 1]\n",
        "    },\n",
        "    \"DecisionTreeClassifier\": {\n",
        "        # \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "        # \"splitter\": [\"best\", \"random\"],\n",
        "        # \"max_depth\": [None, 5, 10, 15, 20, 25],\n",
        "        \"min_samples_split\": [2, 5, 8, 11, 14],\n",
        "        \"min_samples_leaf\": [1, 3, 5, 7, 9, 11],\n",
        "    },\n",
        "    \"HistGradientBoostingClassifier\": {\n",
        "        # \"learning_rate\": [0.1, 0.01, 0.001],\n",
        "        \"max_iter\": [100, 150, 200, 250],\n",
        "        \"max_depth\": [None, 5, 10, 15, 20, 25],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d68c1b",
      "metadata": {
        "id": "93d68c1b"
      },
      "outputs": [],
      "source": [
        "def model_evaluation(y_true, y_pred):\n",
        "    accuracy_score_ = accuracy_score(y_true, y_pred)\n",
        "    f1_score_ = f1_score(y_true, y_pred)\n",
        "    recall_score_ = recall_score(y_true, y_pred)\n",
        "\n",
        "    return accuracy_score_, f1_score_, recall_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c5ff45",
      "metadata": {
        "id": "09c5ff45"
      },
      "outputs": [],
      "source": [
        "def run_training_experiment(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        models: dict,\n",
        "        params: dict,\n",
        "        experiment: str,\n",
        "        type: str\n",
        ") -> dict:\n",
        "    print(\">>>>>>>>>>> Running Training Experiment <<<<<<<<<<<<\")\n",
        "    models_uri = dict()\n",
        "    for m, estimator in models.items():\n",
        "        print(f\"\\nModel: {m}\")\n",
        "\n",
        "        params = parameters[m]\n",
        "\n",
        "        grid_cv = GridSearchCV(\n",
        "            estimator=estimator,\n",
        "            param_grid=params,\n",
        "            cv=3,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        grid_cv.fit(X_train, y_train)\n",
        "        y_result = grid_cv.predict(X_train)\n",
        "\n",
        "        accuracy_score_, f1_score_, recall_score_ = model_evaluation(y_train, y_result)\n",
        "\n",
        "        if accuracy_score != 1:\n",
        "\n",
        "            mlflow.set_experiment(experiment)\n",
        "            with mlflow.start_run(run_name=m):\n",
        "                model_ = mlflow.sklearn.log_model(sk_model=grid_cv.best_estimator_, artifact_path=m)\n",
        "                models_uri[m] = model_.model_uri\n",
        "                mlflow.log_params(grid_cv.best_params_)\n",
        "\n",
        "                mlflow.log_metric(\"accuracy_score\", accuracy_score_)\n",
        "                mlflow.log_metric(\"f1_score\", f1_score_)\n",
        "                mlflow.log_metric(\"recall_score\", recall_score_)\n",
        "\n",
        "                mlflow.set_tag(\"Experiment Type\", \"Training\")\n",
        "                mlflow.set_tag(\"Data Type\", type)\n",
        "\n",
        "    print(\"\\n>>>>>>>>>>> Finishing Training Experiment <<<<<<<<<<<<\")\n",
        "    return models_uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8128e8df",
      "metadata": {
        "id": "8128e8df"
      },
      "outputs": [],
      "source": [
        "def run_testing_experiment(\n",
        "        X_test,\n",
        "        y_test,\n",
        "        trained_models: dict,\n",
        "        experiment: str,\n",
        "        type: str\n",
        ") -> None:\n",
        "    print(\"\\n>>>>>>>>>>> Running Testing Experiment <<<<<<<<<<<<\")\n",
        "    for m, run_id in trained_models.items():\n",
        "        print(m, run_id)\n",
        "\n",
        "        loaded_model = mlflow.pyfunc.load_model(run_id)\n",
        "\n",
        "        y_pred_test = loaded_model.predict(X_test)\n",
        "\n",
        "        accuracy_score_, f1_score_, recall_score_ = model_evaluation(y_test, y_pred_test)\n",
        "        print(accuracy_score_, f1_score_, recall_score_)\n",
        "\n",
        "        mlflow.set_experiment(experiment)\n",
        "        with mlflow.start_run(run_name=m):\n",
        "            mlflow.sklearn.log_model(sk_model=loaded_model, artifact_path=m)\n",
        "            mlflow.log_metric(\"accuracy_score\", accuracy_score_)\n",
        "            mlflow.log_metric(\"f1_score\", f1_score_)\n",
        "            mlflow.log_metric(\"recall_score\", recall_score_)\n",
        "\n",
        "            mlflow.set_tag(\"Experiment Type\", \"Testing\")\n",
        "            mlflow.set_tag(\"Data Type\", type)\n",
        "\n",
        "    print(\"\\n>>>>>>>>>>> Finishing Testing Experiment <<<<<<<<<<<<\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176f00dc",
      "metadata": {
        "id": "176f00dc"
      },
      "outputs": [],
      "source": [
        "trained_models = run_training_experiment(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    models,\n",
        "    parameters,\n",
        "    \"training_experiment\",\n",
        "    \"Original data\",\n",
        ")\n",
        "\n",
        "run_testing_experiment(\n",
        "        X_test,\n",
        "        y_test,\n",
        "        trained_models,\n",
        "        \"testing_experiment\",\n",
        "        \"Original data\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25069f71",
      "metadata": {
        "id": "25069f71"
      },
      "source": [
        "### Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84c56ed",
      "metadata": {
        "id": "f84c56ed"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler = scaler.fit(X_b.copy())\n",
        "X_b_scaled = scaler.transform(X_b.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88dab8d6",
      "metadata": {
        "id": "88dab8d6"
      },
      "source": [
        "### Separate Scaled data into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd78ca4a",
      "metadata": {
        "id": "cd78ca4a"
      },
      "outputs": [],
      "source": [
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
        "    X_b_scaled, y_b, test_size=0.2, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55adbc1f",
      "metadata": {
        "id": "55adbc1f"
      },
      "source": [
        "### Model experiment - Scaled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f09fce4d",
      "metadata": {
        "id": "f09fce4d"
      },
      "outputs": [],
      "source": [
        "trained_models_scaled = run_training_experiment(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    models,\n",
        "    parameters,\n",
        "    \"training_experiment\",\n",
        "    \"Scaled data\",\n",
        ")\n",
        "\n",
        "run_testing_experiment(\n",
        "        X_test_scaled,\n",
        "        y_test,\n",
        "        trained_models_scaled,\n",
        "        \"testing_experiment\",\n",
        "        \"Scaled data\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "445c6ca2",
      "metadata": {
        "id": "445c6ca2"
      },
      "source": [
        "## Prediction Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c95558b2",
      "metadata": {
        "id": "c95558b2"
      },
      "source": [
        "### Get best model from MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "735c698e",
      "metadata": {
        "id": "735c698e"
      },
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b76f04",
      "metadata": {
        "id": "63b76f04"
      },
      "outputs": [],
      "source": [
        "def get_all_models(experiment_name: str):\n",
        "    client = MlflowClient()\n",
        "    experiment = client.get_experiment_by_name(experiment_name)\n",
        "\n",
        "    all_models = client.search_runs(\n",
        "        experiment_ids=[experiment.experiment_id],\n",
        "        order_by=[\"metrics.accuracy_score DESC\"],\n",
        "    )\n",
        "\n",
        "    return all_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339d531e",
      "metadata": {
        "id": "339d531e"
      },
      "outputs": [],
      "source": [
        "def get_ideal_models(all_models) -> dict:\n",
        "    models_to_go = dict()\n",
        "\n",
        "    for m in all_models:\n",
        "\n",
        "        model_name = f\"{m.info.run_name} | {m.data.tags[\"Data Type\"]}\"\n",
        "        score = m.data.metrics[\"accuracy_score\"]\n",
        "        if score != 1 and score >= 0.7:\n",
        "\n",
        "            models_to_go[model_name] = score\n",
        "\n",
        "    return models_to_go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f968a2",
      "metadata": {
        "id": "36f968a2"
      },
      "outputs": [],
      "source": [
        "def get_best_model_uri(models: dict) -> dict:\n",
        "    best_model = max(models, key=models.get)\n",
        "    model, data_type = best_model.split(\" | \")\n",
        "\n",
        "    all_trained_models = get_all_models(\"training_experiment\")\n",
        "\n",
        "    output_model = dict()\n",
        "    for m in all_trained_models:\n",
        "        model_comp = m.info.run_name\n",
        "        data_type_comp = m.data.tags[\"Data Type\"]\n",
        "\n",
        "        if model == model_comp and data_type == data_type_comp:\n",
        "            run_id = m.info.run_id\n",
        "\n",
        "            model_uri = f\"runs:/{run_id}/{model}\"\n",
        "            output_model[\"model_name\"] = model\n",
        "            output_model[\"model_uri\"] = model_uri\n",
        "            output_model[\"data_type\"] = data_type\n",
        "\n",
        "    return output_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747bb042",
      "metadata": {
        "id": "747bb042"
      },
      "outputs": [],
      "source": [
        "all_tested_models = get_all_models(\"testing_experiment\")\n",
        "models = get_ideal_models(all_tested_models)\n",
        "model = get_best_model_uri(models)\n",
        "\n",
        "print(f\"Final model:\\n{model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5e078f",
      "metadata": {
        "id": "ea5e078f"
      },
      "source": [
        "### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb62a83a",
      "metadata": {
        "id": "bb62a83a"
      },
      "outputs": [],
      "source": [
        "def make_prediction(model: dict, y_true):\n",
        "    loaded_model = mlflow.pyfunc.load_model(model[\"model_uri\"])\n",
        "\n",
        "    if model[\"data_type\"] == \"Original data\":\n",
        "        y_pred = loaded_model.predict(X_test)\n",
        "    else:\n",
        "        y_pred = loaded_model.predict(X_test_scaled)\n",
        "\n",
        "    acc_score = accuracy_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    return acc_score, conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010832fb",
      "metadata": {
        "id": "010832fb"
      },
      "outputs": [],
      "source": [
        "acc_score, conf_matrix, = make_prediction(model, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cd1e49",
      "metadata": {
        "id": "53cd1e49"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, cbar=False, fmt=\"d\", cmap=\"Purples\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(f\"Confusion Matrix of {model[\"model_name\"]} | Score: {np.round(acc_score, 3)} | {model[\"data_type\"]}\", loc=\"left\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac833fb6",
      "metadata": {
        "id": "ac833fb6"
      },
      "source": [
        "## Neural Network Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe56a66",
      "metadata": {
        "id": "6fe56a66"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}